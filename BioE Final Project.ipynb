{"cells":[{"cell_type":"code","execution_count":147,"metadata":{"id":"zo2N7mTr9IBz"},"outputs":[{"name":"stdout","output_type":"stream","text":["********************************************************************************\n","WARNING: Imported VTK version (9.3) does not match the one used\n","         to build the TVTK classes (9.2). This may cause problems.\n","         Please rebuild TVTK.\n","********************************************************************************\n","\n"]}],"source":["# This project focuses on brain CT image segmentation and denoising using Deep Learning.\n","# Al Smith and Will Newman\n","# c 2024\n","\n","# Importing the necessary libraries:\n","import pydicom\n","from collections import defaultdict\n","import torch\n","import numpy as np\n","import zipfile\n","import os\n","import sys\n","\n","import matplotlib.pyplot as plt\n","from ipywidgets import widgets\n","from scipy.ndimage import label\n","from mayavi import mlab\n","from mpl_toolkits.mplot3d import Axes3D"]},{"cell_type":"markdown","metadata":{},"source":["## Tasks:\n","1) Load data from CQ500\n","    * Download from: http://headctstudy.qure.ai/dataset\n","    * Explore the DICOM Header for voxel size and imaging information (ideally the CT machine model)\n","    * Resolution, dose, parameters, etc.\n","2) Preprocess the data (noise addition, downsampling, agumentation, etc)\n","    * 2a) Add noise similar to low-resolution CT\n","    * 2b) Downsample the images to lower-resolution scale\n","    * 2c) Split data into train/test sets\n","3) Build a 3D U-Net model for segmentation\n","    * 3a) start with training the model on CQ500 and normal masks\n","    * 3b) train the model on CQ500 with noise added\n","    * 3c) train the model on CQ500 with images processed by denoising model\n","4) Denoising Model for noisy CT images\n","5) Train the model\n","6) Evaluate the model"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["completed extraction of CT 121\n","completed extraction of CT 122\n","completed extraction of CT 123\n","completed extraction of CT 124\n","completed extraction of CT 125\n","completed extraction of CT 126\n","completed extraction of CT 127\n","completed extraction of CT 128\n","completed extraction of CT 129\n","completed extraction of CT 130\n","completed extraction of CT 131\n","completed extraction of CT 132\n","completed extraction of CT 133\n","completed extraction of CT 134\n","completed extraction of CT 135\n","completed extraction of CT 136\n","completed extraction of CT 137\n","completed extraction of CT 138\n","completed extraction of CT 139\n","completed extraction of CT 140\n","completed extraction of CT 141\n","completed extraction of CT 142\n","completed extraction of CT 143\n","completed extraction of CT 144\n","completed extraction of CT 145\n","completed extraction of CT 146\n","completed extraction of CT 147\n","completed extraction of CT 148\n","completed extraction of CT 149\n","completed extraction of CT 150\n","completed extraction of CT 151\n","completed extraction of CT 152\n","completed extraction of CT 153\n","completed extraction of CT 154\n","completed extraction of CT 155\n","completed extraction of CT 156\n","completed extraction of CT 157\n","completed extraction of CT 158\n","completed extraction of CT 159\n","completed extraction of CT 160\n","completed extraction of CT 161\n","completed extraction of CT 162\n","completed extraction of CT 163\n","completed extraction of CT 164\n","completed extraction of CT 165\n","completed extraction of CT 166\n","completed extraction of CT 167\n","completed extraction of CT 168\n","completed extraction of CT 169\n","completed extraction of CT 170\n","completed extraction of CT 171\n","completed extraction of CT 172\n","completed extraction of CT 173\n","completed extraction of CT 174\n","completed extraction of CT 175\n","completed extraction of CT 176\n","completed extraction of CT 177\n","completed extraction of CT 178\n","completed extraction of CT 179\n","completed extraction of CT 180\n","completed extraction of CT 181\n","completed extraction of CT 182\n","completed extraction of CT 183\n","completed extraction of CT 184\n","completed extraction of CT 185\n","completed extraction of CT 186\n","completed extraction of CT 187\n","completed extraction of CT 188\n","completed extraction of CT 189\n","completed extraction of CT 190\n","completed extraction of CT 191\n","completed extraction of CT 192\n","completed extraction of CT 193\n","completed extraction of CT 194\n","completed extraction of CT 195\n","completed extraction of CT 196\n","completed extraction of CT 197\n","completed extraction of CT 198\n","completed extraction of CT 199\n","completed extraction of CT 200\n","completed extraction of CT 201\n","completed extraction of CT 202\n","completed extraction of CT 203\n","completed extraction of CT 204\n","completed extraction of CT 205\n","completed extraction of CT 206\n","completed extraction of CT 207\n","completed extraction of CT 208\n","completed extraction of CT 209\n","completed extraction of CT 210\n","completed extraction of CT 211\n","completed extraction of CT 212\n","completed extraction of CT 213\n","completed extraction of CT 214\n","completed extraction of CT 215\n","completed extraction of CT 216\n","completed extraction of CT 217\n","completed extraction of CT 218\n","completed extraction of CT 219\n","completed extraction of CT 220\n","completed extraction of CT 221\n","completed extraction of CT 222\n","completed extraction of CT 223\n","completed extraction of CT 224\n","completed extraction of CT 225\n","completed extraction of CT 226\n","completed extraction of CT 227\n","completed extraction of CT 228\n","completed extraction of CT 229\n","completed extraction of CT 230\n","completed extraction of CT 231\n","completed extraction of CT 232\n","completed extraction of CT 233\n","completed extraction of CT 234\n","completed extraction of CT 235\n","completed extraction of CT 236\n","completed extraction of CT 237\n","completed extraction of CT 238\n","completed extraction of CT 239\n","completed extraction of CT 240\n","completed extraction of CT 241\n","completed extraction of CT 242\n","completed extraction of CT 243\n","completed extraction of CT 244\n","completed extraction of CT 245\n","completed extraction of CT 246\n","completed extraction of CT 247\n","completed extraction of CT 248\n","completed extraction of CT 249\n","completed extraction of CT 250\n","completed extraction of CT 251\n","completed extraction of CT 252\n","completed extraction of CT 253\n","completed extraction of CT 254\n","completed extraction of CT 255\n","completed extraction of CT 256\n","completed extraction of CT 257\n","completed extraction of CT 258\n","completed extraction of CT 259\n","completed extraction of CT 260\n","completed extraction of CT 261\n","completed extraction of CT 262\n","completed extraction of CT 263\n","completed extraction of CT 264\n","completed extraction of CT 265\n","completed extraction of CT 266\n","completed extraction of CT 267\n","completed extraction of CT 268\n","completed extraction of CT 269\n","completed extraction of CT 270\n","completed extraction of CT 271\n","completed extraction of CT 272\n","completed extraction of CT 273\n","completed extraction of CT 274\n","completed extraction of CT 275\n","completed extraction of CT 276\n","completed extraction of CT 277\n","completed extraction of CT 278\n","completed extraction of CT 279\n","completed extraction of CT 280\n","completed extraction of CT 281\n","completed extraction of CT 282\n","completed extraction of CT 283\n","completed extraction of CT 284\n","completed extraction of CT 285\n","completed extraction of CT 286\n","completed extraction of CT 287\n","completed extraction of CT 288\n","completed extraction of CT 289\n","completed extraction of CT 290\n","completed extraction of CT 291\n","completed extraction of CT 292\n","completed extraction of CT 293\n","completed extraction of CT 294\n","completed extraction of CT 295\n","completed extraction of CT 296\n","completed extraction of CT 297\n","completed extraction of CT 298\n","completed extraction of CT 299\n","completed extraction of CT 300\n","completed extraction of CT 301\n","completed extraction of CT 302\n","completed extraction of CT 303\n","completed extraction of CT 304\n","completed extraction of CT 305\n","completed extraction of CT 306\n","completed extraction of CT 307\n","completed extraction of CT 308\n","completed extraction of CT 309\n","completed extraction of CT 310\n","completed extraction of CT 311\n","completed extraction of CT 312\n","completed extraction of CT 313\n","completed extraction of CT 314\n","completed extraction of CT 315\n","completed extraction of CT 316\n","completed extraction of CT 317\n","completed extraction of CT 318\n","completed extraction of CT 319\n","completed extraction of CT 320\n","completed extraction of CT 321\n","completed extraction of CT 322\n","completed extraction of CT 323\n","completed extraction of CT 324\n","completed extraction of CT 325\n","completed extraction of CT 326\n","completed extraction of CT 327\n","completed extraction of CT 328\n","completed extraction of CT 329\n","completed extraction of CT 330\n","completed extraction of CT 331\n","completed extraction of CT 332\n","completed extraction of CT 333\n","completed extraction of CT 334\n","completed extraction of CT 335\n","completed extraction of CT 336\n","completed extraction of CT 337\n","completed extraction of CT 338\n","completed extraction of CT 339\n","completed extraction of CT 340\n","completed extraction of CT 341\n","completed extraction of CT 342\n","completed extraction of CT 343\n","completed extraction of CT 344\n","completed extraction of CT 345\n","completed extraction of CT 346\n","completed extraction of CT 347\n","completed extraction of CT 348\n","completed extraction of CT 349\n","completed extraction of CT 350\n","completed extraction of CT 351\n","completed extraction of CT 352\n","completed extraction of CT 353\n","completed extraction of CT 354\n","completed extraction of CT 355\n","completed extraction of CT 356\n","completed extraction of CT 357\n","completed extraction of CT 358\n","completed extraction of CT 359\n","completed extraction of CT 360\n","completed extraction of CT 361\n","completed extraction of CT 362\n","completed extraction of CT 363\n","completed extraction of CT 364\n","completed extraction of CT 365\n","completed extraction of CT 366\n","completed extraction of CT 367\n","completed extraction of CT 368\n","completed extraction of CT 369\n","completed extraction of CT 370\n","completed extraction of CT 371\n","completed extraction of CT 372\n","completed extraction of CT 373\n","completed extraction of CT 374\n","completed extraction of CT 375\n","completed extraction of CT 376\n","completed extraction of CT 377\n","completed extraction of CT 378\n","completed extraction of CT 379\n","completed extraction of CT 380\n","completed extraction of CT 381\n","completed extraction of CT 382\n","completed extraction of CT 383\n","completed extraction of CT 384\n","completed extraction of CT 385\n","completed extraction of CT 386\n","completed extraction of CT 387\n","completed extraction of CT 388\n","completed extraction of CT 389\n","completed extraction of CT 390\n","completed extraction of CT 391\n","completed extraction of CT 392\n","completed extraction of CT 393\n","completed extraction of CT 394\n","completed extraction of CT 395\n","completed extraction of CT 396\n","completed extraction of CT 397\n","completed extraction of CT 398\n","completed extraction of CT 399\n","completed extraction of CT 400\n","completed extraction of CT 401\n","completed extraction of CT 402\n","completed extraction of CT 403\n","completed extraction of CT 404\n","completed extraction of CT 405\n","completed extraction of CT 406\n","completed extraction of CT 407\n","completed extraction of CT 408\n","completed extraction of CT 409\n","completed extraction of CT 410\n","completed extraction of CT 411\n","completed extraction of CT 412\n","completed extraction of CT 413\n","completed extraction of CT 414\n","completed extraction of CT 415\n","completed extraction of CT 416\n","completed extraction of CT 417\n","completed extraction of CT 418\n","completed extraction of CT 419\n","completed extraction of CT 420\n","completed extraction of CT 421\n","completed extraction of CT 422\n","completed extraction of CT 423\n","completed extraction of CT 424\n","completed extraction of CT 425\n","completed extraction of CT 426\n","completed extraction of CT 427\n","completed extraction of CT 428\n","completed extraction of CT 429\n","completed extraction of CT 430\n","completed extraction of CT 431\n","completed extraction of CT 432\n","completed extraction of CT 433\n","completed extraction of CT 434\n","completed extraction of CT 435\n","completed extraction of CT 436\n","completed extraction of CT 437\n","completed extraction of CT 438\n","completed extraction of CT 439\n","completed extraction of CT 440\n","completed extraction of CT 441\n","completed extraction of CT 442\n","completed extraction of CT 443\n","completed extraction of CT 444\n","completed extraction of CT 445\n","completed extraction of CT 446\n","completed extraction of CT 447\n","completed extraction of CT 448\n","completed extraction of CT 449\n","completed extraction of CT 450\n","completed extraction of CT 451\n","completed extraction of CT 452\n","completed extraction of CT 453\n","completed extraction of CT 454\n","completed extraction of CT 455\n","completed extraction of CT 456\n","completed extraction of CT 457\n","completed extraction of CT 458\n","completed extraction of CT 459\n","completed extraction of CT 460\n","completed extraction of CT 461\n","completed extraction of CT 462\n","completed extraction of CT 463\n","completed extraction of CT 464\n","completed extraction of CT 465\n","completed extraction of CT 466\n","completed extraction of CT 467\n","completed extraction of CT 468\n","completed extraction of CT 469\n","completed extraction of CT 470\n","completed extraction of CT 471\n","completed extraction of CT 472\n","completed extraction of CT 473\n","completed extraction of CT 474\n","completed extraction of CT 475\n","completed extraction of CT 476\n","completed extraction of CT 477\n","completed extraction of CT 478\n","completed extraction of CT 479\n","completed extraction of CT 480\n","completed extraction of CT 481\n","completed extraction of CT 482\n","completed extraction of CT 483\n","completed extraction of CT 484\n","completed extraction of CT 485\n","completed extraction of CT 486\n","completed extraction of CT 487\n","completed extraction of CT 488\n","completed extraction of CT 489\n","completed extraction of CT 490\n","Extraction completed.\n"]}],"source":["# Extract zip files from CQ500\n","data_dir = './CQ500'\n","extract_dir = '/media/hal9000/Database/CQ500_extracted'\n","\n","# Create the extraction directory if it doesn't exist\n","os.makedirs(extract_dir, exist_ok=True)\n","\n","for i in range(121, 491): # CQ500 scan 120 corrupted...\n","    zip_file = data_dir + \"/CQ500-CT-{}.zip\".format(i)\n","    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n","        # Extract all the contents of the zip file in the extraction directory\n","        zip_ref.extractall(path=extract_dir)\n","    print(\"completed extraction of CT\", i)\n","\n","print(\"Extraction completed.\")"]},{"cell_type":"code","execution_count":185,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[185], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[1;32m     48\u001b[0m base_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/media/hal9000/Database/CQ500_extracted\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Adjust this path\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m dicom_volumes \u001b[38;5;241m=\u001b[39m \u001b[43mload_dicom_series_volumes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of series with loaded volumes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dicom_volumes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[185], line 39\u001b[0m, in \u001b[0;36mload_dicom_series_volumes\u001b[0;34m(base_directory, num_dicom)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m slices:\n\u001b[1;32m     38\u001b[0m                 series_uid \u001b[38;5;241m=\u001b[39m slices[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mSeriesInstanceUID\n\u001b[0;32m---> 39\u001b[0m                 volume \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([s[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mpixel_array \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m slices])\n\u001b[1;32m     40\u001b[0m                 series_volumes[series_uid]\u001b[38;5;241m.\u001b[39mappend(volume)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","Cell \u001b[0;32mIn[185], line 39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m slices:\n\u001b[1;32m     38\u001b[0m                 series_uid \u001b[38;5;241m=\u001b[39m slices[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mSeriesInstanceUID\n\u001b[0;32m---> 39\u001b[0m                 volume \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpixel_array\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m slices])\n\u001b[1;32m     40\u001b[0m                 series_volumes[series_uid]\u001b[38;5;241m.\u001b[39mappend(volume)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydicom/dataset.py:1955\u001b[0m, in \u001b[0;36mDataset.pixel_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpixel_array\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the pixel data as a :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[1;32m   1943\u001b[0m \n\u001b[1;32m   1944\u001b[0m \u001b[38;5;124;03m    .. versionchanged:: 1.4\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[38;5;124;03m        :class:`numpy.ndarray`.\u001b[39;00m\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_pixel_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydicom/dataset.py:1512\u001b[0m, in \u001b[0;36mDataset.convert_pixel_data\u001b[0;34m(self, handler_name)\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_pixel_data_using_handler(handler_name)\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1512\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_pixel_data_without_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydicom/dataset.py:1604\u001b[0m, in \u001b[0;36mDataset._convert_pixel_data_without_handler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m available_handlers:\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1604\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_pixel_data_conversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1605\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydicom/dataset.py:1631\u001b[0m, in \u001b[0;36mDataset._do_pixel_data_conversion\u001b[0;34m(self, handler)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do the actual data conversion using the given handler.\"\"\"\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;66;03m# Use the handler to get a 1D numpy array of the pixel data\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;66;03m# Will raise an exception if no pixel data element\u001b[39;00m\n\u001b[0;32m-> 1631\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pixeldata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pixel_array \u001b[38;5;241m=\u001b[39m reshape_pixel_array(\u001b[38;5;28mself\u001b[39m, arr)\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;66;03m# Some handler/transfer syntax combinations may need to\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;66;03m#   convert the color space from YCbCr to RGB\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydicom/pixel_data_handlers/pillow_handler.py:223\u001b[0m, in \u001b[0;36mget_pixeldata\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYBR\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m photometric_interpretation:\n\u001b[1;32m    222\u001b[0m     im\u001b[38;5;241m.\u001b[39mdraft(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYCbCr\u001b[39m\u001b[38;5;124m'\u001b[39m, (rows, columns))\n\u001b[0;32m--> 223\u001b[0m pixel_bytes\u001b[38;5;241m.\u001b[39mextend(\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    225\u001b[0m params \u001b[38;5;241m=\u001b[39m get_j2k_parameters(pixel_data)\n\u001b[1;32m    226\u001b[0m j2k_precision \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mint\u001b[39m, params\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, bits_stored))\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Image.py:729\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    727\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/Jpeg2KImagePlugin.py:278\u001b[0m, in \u001b[0;36mJpeg2KImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m     t3 \u001b[38;5;241m=\u001b[39m (t[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers, t[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m3\u001b[39m], t[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtile \u001b[38;5;241m=\u001b[39m [(t[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, t[\u001b[38;5;241m2\u001b[39m], t3)]\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/ImageFile.py:234\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder\u001b[38;5;241m.\u001b[39mpulls_fd:\n\u001b[1;32m    233\u001b[0m     decoder\u001b[38;5;241m.\u001b[39msetfd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp)\n\u001b[0;32m--> 234\u001b[0m     err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     b \u001b[38;5;241m=\u001b[39m prefix\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def load_dicom_series_volumes(base_directory, num_dicom):\n","    assert num_dicom <= 491 and num_dicom > 0\n","    series_volumes = defaultdict(list)\n","    # Track the number of DICOM files processed\n","    dicom_file_count = 0\n","\n","    # Loop through each CQ500-CT-# directory\n","    for i in range(num_dicom):\n","        if i == 120:  # Skip the missing directory\n","            continue\n","        \n","        # Construct the directory path\n","        case_dir = os.path.join(base_directory, f\"CQ500CT{i} CQ500CT{i}\", \"Unknown Study\")\n","        \n","        if os.path.exists(case_dir):\n","            # Walk through all files in the series directories within the \"Unknown Study\" directory\n","            for root, dirs, files in os.walk(case_dir):\n","                for dir in dirs:\n","                    series_path = os.path.join(root, dir)\n","                    slices = []\n","                    # Collect all DICOM slices in the series directory\n","                    for slice_file in os.listdir(series_path):\n","                        if slice_file.lower().endswith('.dcm'):\n","                            full_path = os.path.join(series_path, slice_file)\n","                            try:\n","                                # Read the DICOM file\n","                                dicom_slice = pydicom.dcmread(full_path)\n","                                # Append the slice and its position for later sorting\n","                                slices.append((dicom_slice, dicom_slice.ImagePositionPatient[2]))\n","                                dicom_file_count += 1\n","                            except Exception as e:\n","                                print(f\"Failed to read {slice_file} as DICOM: {e}\")\n","\n","                    # Sort slices based on the z-coordinate (ImagePositionPatient[2])\n","                    slices.sort(key=lambda x: x[1])\n","                    # Stack the pixel data from sorted slices to form a 3D volume\n","                    if slices:\n","                        series_uid = slices[0][0].SeriesInstanceUID\n","                        volume = np.stack([s[0].pixel_array for s in slices])\n","                        series_volumes[series_uid].append(volume)\n","        else:\n","            print(f\"Directory does not exist: {case_dir}\")\n","\n","    print(f\"Processed {dicom_file_count} DICOM files.\")\n","    return series_volumes\n","\n","# Usage example\n","base_directory = '/media/hal9000/Database/CQ500_extracted'  # Adjust this path\n","dicom_volumes = load_dicom_series_volumes(base_directory, 4)\n","print(f\"Number of series with loaded volumes: {len(dicom_volumes)}\")"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[],"source":["# Apply window and level to a 2D numpy array of DICOM data\n","def apply_window_level(data, lb, ub):\n","    windowed_data = np.clip(data, lb, ub)\n","    normalized_data = (windowed_data - lb) / (ub - lb)  # Normalize between 0 and 1\n","    return normalized_data\n","\n","# Remove unnecessary CSF spaces from the mask\n","def remove_mask_below_slice(volume_mask, slice_index):\n","    \"\"\"\n","    Set the mask to False for all slices below the specified index.\n","\n","    Parameters:\n","    - volume_mask: 3D numpy array (boolean) of the mask.\n","    - slice_index: Integer, the index below which the mask should be removed.\n","    \"\"\"\n","    # Set all slices below the specified index to False\n","    volume_mask[:slice_index, :, :] = False\n","    return volume_mask\n"]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[],"source":["# Largest connected component segmentation\n","def create_spherical_mask(shape, center, radius):\n","    z, y, x = np.ogrid[:shape[0], :shape[1], :shape[2]]\n","    dist_from_center = (z - center[0])**2 + (y - center[1])**2 + (x - center[2])**2\n","    return dist_from_center <= radius**2\n","\n","\n","def largest_connected_component_3d(volume_data, lb, center, radius, threshold=0.4):\n","    \"\"\"\n","    Find the largest connected component in a 3D volume that intersects with a specified spherical region.\n","\n","    Parameters:\n","    - volume_data: 3D numpy array of DICOM data.\n","    - lb: Lower bound to create a binary mask for values of interest.\n","    - center: Tuple, the center coordinates (z, y, x) of the volume.\n","    - radius: Integer, the radius used to define the spherical region.\n","\n","    Returns:\n","    - 3D mask (boolean array) of the same shape as volume_data for the largest component intersecting the sphere.\n","    \"\"\"\n","    # Generate the binary mask\n","    slice_index = int(volume_data.shape[0] * 0.4)\n","    binary_mask = volume_data < lb\n","    binary_mask = remove_mask_below_slice(binary_mask, slice_index)\n","\n","    # Label all components\n","    labeled_volume, num_features = label(binary_mask)\n","    if num_features == 0:\n","        return np.zeros_like(volume_data, dtype=bool)  # No components found\n","\n","    # Generate the spherical mask\n","    spherical_mask = create_spherical_mask(volume_data.shape, center, radius)\n","\n","    # Find labels intersecting the spherical mask\n","    intersecting_labels = np.unique(labeled_volume[spherical_mask])\n","\n","    # Calculate the size of each intersecting component and select the largest\n","    largest_label = None\n","    max_size = 0\n","    for label_idx in intersecting_labels:\n","        if label_idx == 0:\n","            continue  # Skip background\n","        component_mask = labeled_volume == label_idx\n","        component_size = np.sum(component_mask)\n","        if component_size > max_size:\n","            max_size = component_size\n","            largest_label = label_idx\n","\n","    return labeled_volume == largest_label if largest_label is not None else np.zeros_like(volume_data, dtype=bool)\n"]},{"cell_type":"code","execution_count":182,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b35cdc7f75a643a4abde71e663f31a71","version_major":2,"version_minor":0},"text/plain":["interactive(children=(IntSlider(value=0, description='Slice Index:', max=238), Output()), _dom_classes=('widge…"]},"execution_count":182,"metadata":{},"output_type":"execute_result"}],"source":["# Visualize Loaded DICOM Data\n","lb = 1040\n","ub = 1080\n","\n","# Assume dicom_volumes is already loaded as per the previous part of our discussion\n","series_selection = 1\n","series_uid = list(dicom_volumes.keys())[series_selection]\n","volume = dicom_volumes[series_uid][0]  # Get the first volume of the first series\n","\n","center = (volume.shape[0] // 2, volume.shape[1] // 2, volume.shape[2] // 2)\n","radius = int(volume.shape[0] // 6)  # Define the radius as desired\n","volume_mask = remove_mask_below_slice(largest_connected_component_3d(volume, lb, center, radius), volume.shape[0] * 2 // 5)\n","\n","# Function to display a single slice\n","def view_slice(slice_index):\n","    plt.figure(figsize=(4, 4))\n","    processed_image = apply_window_level(volume[slice_index], lb, ub)\n","    \n","    # Overlay the 3D mask on the corresponding slice\n","    overlay = np.zeros(processed_image.shape + (4,))  # RGBA\n","    overlay[..., 0] = 1.0  # Red channel\n","    overlay[..., 3] = volume_mask[slice_index] * 0.5  # Semi-transparent where the mask is True\n","\n","    plt.imshow(processed_image, cmap='gray')\n","    plt.imshow(overlay)\n","    plt.axis('off')\n","    plt.title(f'Slice {slice_index + 1}')\n","    plt.show()\n","\n","# Slider to select the slice index\n","slice_slider = widgets.IntSlider(\n","    value=0,\n","    min=0,\n","    max=volume.shape[0] - 1,  # max slice index\n","    step=1,\n","    description='Slice Index:',\n","    continuous_update=True\n",")\n","\n","# Use ipywidgets' interactive functionality to bind the slider and the display function\n","widgets.interactive(view_slice, slice_index=slice_slider)"]},{"cell_type":"code","execution_count":180,"metadata":{},"outputs":[],"source":["# Visualize the CSF Space Segmentation Mask in 3D dynamic viewer\n","def visualize_3d_mask(volume_mask):\n","    \"\"\"Visualize a 3D mask using mayavi's volume rendering capabilities.\"\"\"\n","    # Create a figure\n","    fig = mlab.figure(bgcolor=(0, 0, 0), size=(800, 800))\n","    \n","    # Visualize the volume mask: 1s are turned to True, 0s to False\n","    src = mlab.pipeline.scalar_field(volume_mask.astype(int))\n","    # Threshold to visualize only the 1s\n","    mlab.pipeline.iso_surface(src, contours=[volume_mask.min()+0.5, volume_mask.max()], opacity=0.4, color=(1, 0, 0))\n","    \n","    # Enhance the view\n","    mlab.view(azimuth=180, elevation=180, distance=400)\n","    mlab.roll(180)\n","    \n","    # Add axes and outline for better visual orientation\n","    mlab.outline(src, color=(1, 1, 1))\n","    mlab.axes(src, color=(1, 1, 1), xlabel='X', ylabel='Y', zlabel='Z')\n","\n","    # Show the plot\n","    mlab.show()\n","\n","# Assuming volume_mask is the mask calculated earlier\n","visualize_3d_mask(volume_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Task #1 Load data and explore the DICOM header for voxel size and imaging information"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Task #2 Preprocess the data\n","# Task #2b Add noise similar to low-resolution CT\n","\n","# Task #2c Downsample the images to lower-resolution scale\n","\n","# Task #2d Split the data into training and testing sets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Task #3 Build a 3D U-Net model for segmentation\n","# Task #3a Start with training the model on CQ500 and normal masks\n","\n","# Task #3b Train the model on CQ500 with noise added\n","\n","# Task #3c Train the model on CQ500 with images processed by denoising model"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
